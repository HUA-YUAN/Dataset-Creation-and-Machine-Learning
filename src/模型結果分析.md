
<h2 align="center">
Step7: 模型結果分析
</h2>


### 1. 模型測試階段


經過 [Step6](模型超參數調整.md) 網格搜索方法後，我們在設定範圍內得到一組最佳超參數。
因此，現在可以利用這組超參數訓練一個新的模型，並使用測試集來評估新模型的最終表現。


```python
def regressor_testing(seed, max_depth, n_estimators, feature, x_test, y_test, x_train_val, y_train_val): 
    #Seed Number To make sure the productivity of the model
    np.random.seed(seed)

    # New Model Training 
    final_best_param_rf_reg = RandomForestRegressor(max_depth=max_depth, n_estimators=n_estimators, max_features='sqrt')
    final_best_param_rf_reg.fit(x_train_val, y_train_val)

    # Prediction results of training and testing  
    final_predicted_value1 = np.round(final_best_param_rf_reg.predict(x_train_val))
    predicted_value3 = np.round(final_best_param_rf_reg.predict(x_test))
        
    # Calculate the prediction error of the training dataset
    y_train_val, final_predicted_value1 = np.array(y_train_val),np.array(final_predicted_value1)
    final_train_mae = np.sum(np.abs(y_train_val - final_predicted_value1)) / len(y_train_val)
    
    # Calculate the prediction error of the testing dataset
    y_test, predicted_value3 = np.array(y_test), np.array(predicted_value3)
    test_mae = np.sum(np.abs(y_test - predicted_value3)) / len(y_test)

    return final_best_param_rf_reg, final_train_mae, test_mae
```


### 2. 特徵重要性分析


下方為的特徵重要性分析圖的實作範例，對預測結果而言，透過特徵重要性分析，
可以發現在所有特徵中，哪一些特徵的重要程度較高，進而篩選出較適合的特徵作為模型輸入。


```python
def randomforest_feature_importances(final_best_param_rf_reg):
    feature_importances = final_best_param_rf_reg.feature_importances_   
    col_names = ["Max","Min","P2P","Mean(ABS)","STD"] 
    plt.figure(dpi=150)
    importances_bar = plt.bar(col_names,feature_importances,color='indigo')
    plt.bar_label(importances_bar,fmt='%.4f',label_type='edge')
    plt.title('Feature Importances',fontsize=20, fontweight='bold')
    plt.ylim(0,0.5) 
    plt.show() 
```


<p align="center">
<img src="/images/特徵重要性分析範例圖.png" alt="drawing" width="50%"/>
</p>


### 3. 模型預測結果


最後，我們可以將模型的預測結果視覺化，從圖中可以更清楚看出各資料集的預測情況。
以下方的測試集預測結果為例，從圖中可以看到在加速度觀測值位處 100 至 150 的資料點，其被低估的情形較明顯。

```python
def draw_regressor_result_val_test(y_fold, predicted_value, data_set): 
    fig, ax = plt.subplots(dpi=150)
    ax.scatter(y_fold, predicted_value, color = '#88c999')
    ax.plot([0, 350], [0, 350], 'k-', lw=2)
    plt.legend(['$\mathregular{R^{2}}$: ' + str(round(r2_score(y_fold, predicted_value),2))], loc='best')
    
    if data_set == "final_train":
        plt.title('Prediction Results for Acceleration \n(Training)',fontsize=20, fontweight='bold')
    
    if data_set == "test":
        plt.title("Prediction Results for Acceleration \n(Testing)",fontsize=20, fontweight='bold')
    
    plt.xlim(0,350) 
    plt.ylim(0,350)     
    ax.set_xlabel('Observed Acceleration',fontsize=16)
    ax.set_ylabel('Predicted Acceleration',fontsize=16)
    plt.show()

```

<p align="center">
<img src="/images/模型訓練集結果範例圖.png" alt="drawing" width="50%"/>
<img src="/images/模型測試集結果範例圖.png" alt="drawing" width="50%"/>
</p>


